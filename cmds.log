  535  mkdir A2
  536  cd WS4
  537  ls
  538  cd ~/A2
  539  ls
  540  history
  541  head -n 1 amazon_reviews_us_Books_v1_02.tsv
  542  clear
  543  script a2.txt
  544  rm a2.txt
  545  history
  546  script a2.txt
  547  rm a2.txt
  548  history
  549  ls
  550  total=0;count=0
  551  mkdir CUSTOMERS PRODUCTS
  552  head -n 1 amazon_reviews_us_Books_v1_02.tsv
  553  cd A2
  554  ls
  555  history
  556  ls
  557  head -n 1 amazon_reviews_us_Books_v1_02.tsv
  558  head customerids.txt.sorted.uniqcount.reversed
  559  CUSTMERIDS= "$(awk '{print $$2}' < customerids.txt.sorted.uniqcount.reversed"
  560  CUSTMERIDS= "$(awk '{print $$2}' < customerids.txt.sorted.uniqcount.reversed";
  561  head;
  562  CUSTMERIDS= "$(awk '{print $2}' < customerids.txt.sorted.uniqcount.reversed"
  563  cat UNIQ_IDS
  564  echo UNIQ_IDS
  565  echo $UNIQ_IDS
  566  head customerids.txt.sorted.uniqcount.reversed
  567  history
  568  cut -d " " -f 2  customerids.txt.sorted.uniqcount.reversed> customerids.txt
  569  head customerids.txt
  570  head customerids.txt.sorted.uniqcount.reversed
  571  head -100 head customerids.txt.sorted.uniqcount.reversed
  572  head -100 head customerids.txt.sorted.uniqcount.reversed >customerids.100.txt
  573  head -100 customerids.txt.sorted.uniqcount.reversed >customerids.100.txt
  574  ls
  575  head customerids.100.txt
  576  CUSTMERIDS= "$(awk '{print $2}' < customerids.100.txt"; | sort | uniq)"
  577  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  578  for i in UNIQ_IDS; do egrep "	^\\S+ +$i	" amazon_reviews_us_Books_v1_02.tsv > $i.txt; done;
  579  ls
  580  for i in UNIQ_IDS; do egrep "	^\\S+ +$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  581  cd CUSTOMERS
  582  ls
  583  cd ..
  584  ls
  585  echo $UNIQ_IDS
  586  ls
  587  head UNIQ_IDS.txt
  588  cat UNIQ_IDS.txt
  589  rm UNIQ_IDS.txt
  590  cd CUSTOMERS
  591  ls
  592  cat UNIQ_IDS.txt
  593  rm UNIQ_IDS.txt
  594  cd ..
  595  echo $UNIQ_IDS
  596  for i in UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  597  ls
  598  cd CUSTOMERS
  599  ls
  600  cat UNIQ_IDS.txt
  601  rm UNIQ_IDS.txt
  602  for i in UNIQ_IDS; do egrep "	^\\S+ +$i	" > CUSTOMERS/$i.txt; done;
  603  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  604  for i in $UNIQ_IDS; do "egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv" > CUSTOMERS/$i.txt; done;
  605  ls
  606  cd ..
  607  ls
  608  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  609  ls
  610  cd CUSTOMERS
  611  ;s
  612  ls
  613  cat 51706075.txt
  614  ls
  615  cd ..
  616  rm -r CUSTOMERS
  617  ls
  618  mkdir CUSTOMERS
  619  history
  620  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv >cut -d " " -f 9 45041039.txt > 45041039.helpfulness.txt CUSTOMERS/$i.txt; done;
  621  rm -r CUSTOMERS
  622  for i in $UNIQ_IDS; do egrep "   $i      " amazon_reviews_us_Books_v1_02.tsv | > tempCustomers/$i.txt; done;
  623  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCUSTOMERS/$i.txt; done;
  624  ls
  625  mkdir tempCustomers
  626  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCUSTOMERS/$i.txt; done;
  627  for i in $UNIQ_IDS; do egrep "   $i      " amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  628  ls
  629  mkdir CUSTOMERS
  630  for i in $UNIQ_IDS; do egrep "	$i	 " amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  631  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
  632  ls
  633  cd A2
  634  ls
  635  cd tempCustomers
  636  ls
  637  $UNIQ_IDS
  638  echo $UNIQ_IDS
  639  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  640  cd //
  641  cd ~/A2
  642  ls
  643  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  644  rm -r tempCustomers
  645  rm -r CUSTOMERS
  646  head n -1 amazon_reviews_us_Books_v1_02.tsv
  647  history
  648  for i in $UNIQ_IDS; do egrep "   $i      " amazon_reviews_us_Books_v1_02.tsv | cut -d "  " -f 8,9 amazon_reviews_us_Books_v1_02.tsv> CUSTOMERS/$i.helpfulnessReviews.txt; done
  649  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv | cut -d "	" -f 8,9 amazon_reviews_us_Books_v1_02.tsv> CUSTOMERS/$i.helpfulnessReviews.txt; donefor i in $UNIQ_IDS; do egrep "   $i      " amazon_reviews_us_Books_v1_02.tsv | cut -d "  " -f 8,9 amazon_reviews_us_Books_v1_02.tsv> CUSTOMERS/$i.helpfulnessReviews.txt; done
  650  for i in $UNIQ_IDS; do egrep "   $i       " amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done
  651  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done
  652  la
  653  echo $UNIQ_IDS
  654  echo $UNIQ_IDS| wc
  655  customerids.100.txt wc
  656  customerids.100.txt |wc
  657  wc customerids.100.txt
  658  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  659  mkdir CUSTOMERS
  660  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > CUSTOMERS/$i.txt; done;
  661  cd CUSTOMERS
  662  ls
  663  rm 33993847.txt
  664  cd ..
  665  ls
  666  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv|  cut -d "  " -f 8,9 amazon_reviews_us_Books_v1_02.tsv> CUSTOMERS/$i.helpfulnessReviews.txt ; done;
  667  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv|  cut -d "	" -f 8,9 amazon_reviews_us_Books_v1_02.tsv> CUSTOMERS/$i.helpfulnessReviews.txt ; done;
  668  cd CUSTOMERS
  669  ls
  670  cat 51204643.helpfulnessReviews.txt
  671  echo 51204643.helpfulnessReviews.txt
  672  head 51204643.helpfulnessReviews.txt
  673  total=1;
  674  total > test.txt
  675  vi
  676  cd ..
  677  ls
  678  rm -r CUSTOMERS
  679  mkdir tempCustomers
  680  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
  681  cd tempCustomers
  682  ls
  683  cd //
  684  cd ~/A2
  685  ls
  686  mkdir CUSTOMERS
  687  ls
  688  cd tempCUSTOMERS
  689  cd tempCustomers
  690  ls
  691  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > CUSTOMERS/$i.helpfulnessReviews.txt; done
  692  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > $i.helpfulnessReviews.txt; done
  693  ls
  694  cat 51388692.helpfulnessReviews.txt
  695  cd ..
  696  rm -r tempCustomers
  697  mkdir tempCustomers
  698  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
  699  cd tempCustomers
  700  l
  701  cd ..
  702  ;s
  703  ls
  704  cd CUSTOMERS
  705  ls
  706  cd ~/A2/tempCustomers
  707  ls
  708  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
  709  cd ~/A2/CUSTOMERS
  710  ls
  711  cat 53087372.helpfulnessReviews.txt
  712  cd ..
  713  ls
  714  history
  715  head -100 productids.txt.sorted.uniqcount.reversed >productids.100.txt
  716  ls
  717  wc productids.100.txt
  718  mkdirtempProducts
  719  mkdir tempProducts
  720  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
  721  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempProducts/$i.txt; done
  722  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
  723  cd A2
  724  ls
  725  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
  726  cd tempProducts
  727  ls
  728  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/PRODUCTS/$i.helpfulnessReviews.txt; done
  729  cd ..
  730  cd PRODUCTS
  731  ls
  732  cd ..
  733  alias l='ls -lastr'
  734  ls
  735  l
  736  alias w='ls -la | wc'
  737  vim ~/.bashrc
  738  cd PRODUCTS
  739  l
  740  w
  741  cd..
  742  cd ..
  743  cd CUSTOMERS
  744  w
  745  ls
  746  cd ..
  747  cd tempCustomers
  748  w
  749  ls
  750  cd ..
  751  ls
  752  cd CUSTOMERS
  753  ls
  754  cat 53085673.helpfulnessReviews.txt
  755  w
  756  cd ..
  757  ls
  758  rm -r CUSTOMERS tempCUSTOMERS
  759  ls
  760  rm -r tempCustomers
  761  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
  762  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  763  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done
  764  mkdir tempCustomers
  765  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done
  766  cd A2
  767  cd tempCustomers
  768  ls
  769  cd ..
  770  ls
  771  wc tempcustomerids.100.txt
  772  wc customerids.100.txt
  773  cd tempCustomers
  774  w
  775  cd ..
  776  rm -r tempCustomers
  777  mkdir tempCustomers
  778  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  779  customerids.100.txt
  780  head customerids.100.txt
  781  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  782  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done
  783  cd tempCustomers
  784  w
  785  ls
  786  cd ..
  787  ls
  788  mkdir CUSTOMERS
  789  cd tempCustomers
  790  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
  791  cd ..
  792  cd CUSTOMERS
  793  w
  794  cd ..
  795  sudo apt install datamash
  796  wget http://ftp.gnu.org/gnu/datamash/datamash-1.3.tar.gz
  797  tar -xzf datamash-1.3.tar.gz
  798  cd datamash-1.3
  799  ./configure
  800  make
  801  make check
  802  cd ~/datamash-1.3
  803  sudo make install
  804  ls
  805  cd ~/WS3
  806  ls
  807  mkdir
  808  mkdir test
  809  cd ~/datamash-1.3
  810  rm test
  811  rm -r test
  812  cd ~/A2
  813  ls
  814  cd ~/datamash-1.3
  815  cd datamash-1.3
  816  cd ~/datamash-1.3
  817  ./datamash  -W ppearson 1:2 < ../files/c.txt 
  818  cd //
  819  ls
  820  cd ~
  821  cd A2
  822  ls
  823  cd CUSTOMERS
  824  w
  825  cd ./datamash-a.3
  826  cd ./datamash-1.3
  827  cd ../datamash-1.3
  828  cd ../CUSTOMERS
  829  ls
  830  cd ../datamash-1.3
  831  for file in ../CUSTOMERS/*.helpfulnessReviews.txt; do ./datamash -W ppearson 2:1 < ../CUSTOMERS/$file;done
  832  cd ..
  833  ls
  834  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  835  history
  836  ls
  837  cd CUSTOMERS
  838  l
  839  sls
  840  ls
  841  for i in `cat 33993847.helpfulnessReviews.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
  842  total=0;count=0;
  843  for i in `cat 33993847.helpfulnessReviews.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
  844  echo $total
  845  echo count
  846  echo $count
  847  ls
  848  cd ..
  849  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
  850  cd CUSTOMERS
  851  total=0;count-0;
  852  total=0;count=0;
  853  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done;$count=0;$total=0; done
  854  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done; done
  855  echo $total
  856  echo $count
  857  $total=0; $count=0;
  858  $total=0;$count=0;
  859  $total=0;
  860  total=0;count=0;
  861  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done;count=0;total=0; done
  862  mkdir totalCount
  863  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done; echo countfor i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done; echo count > totalCount/$UNIQ_IDS.toalCount.txt;count=0;total=0; done > totalCount/$UNIQ_IDS.toalCount.txt;count=0;total=0; done
  864  echo $count $total
  865  echo $count $total > test.txt
  866  ls
  867  cat test.txt
  868  rm test.txt
  869  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done; echo total count > totalCount/$UNIQ_IDS.toalCount.txt;count=0;total=0; done
  870  for i in $UNIQ_IDS; do for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done; echo total count > "totalCount/$UNIQ_IDS.toalCount.txt";count=0;total=0; done
  871  ls
  872  cd totalCount.txt
  873  cd totalCount
  874  ls
  875  w
  876  ls -latr
  877  cd ..
  878  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo totalcount > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  879  ls
  880  cd totalCount
  881  w
  882  ls
  883  cat 33993847.totalCount.txt
  884  cd ..
  885  ls
  886  rm -r totalCount
  887  total=;
  888  total=0;count=0;
  889  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo $total $count > totalCount/$i.totalCount.txt;$count=0;$total=0;  done;
  890  echo $toal
  891  echo $total
  892  total=0;count=0;
  893  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo total count > totalCount/$i.totalCount.txt;$count=0;$total=0;  done;
  894  total=0;count=0;
  895  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo total count > totalCount/$i.totalCount.txt;$count=0;$total=0;
  896  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo total count > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  897  for i in $UNIQ_IDS; do >     for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do
  898  >         total=$(echo $total+$i | bc); ((count++));
  899  >     done;
  900  >      echo totalcount > totalCount/$i.totalCount.txt;count=0;total=0;
  901  >  done;
  902  ls
  903  rm done echo 'total =53096149'
  904  ls
  905  mkdir totalCount
  906  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo total count > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  907  cd totalCount
  908  l
  909  ls
  910  cat 33993847.totalCount.txt
  911  cd ..
  912  rm -r totalCount
  913  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
  914  mkdir totalCount
  915  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));     done;      echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  916  cd totalCount
  917  cat 33993847.totalCount.txt
  918  ls
  919  cat 51204643.totalCount.txt
  920  cd ..
  921  ls
  922  for i in ' cat 51204643.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done;
  923  total=0;count=0;
  924  for i in ' cat 51204643.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done;
  925  for i in 'cat 51204643.helpfulnessReviews.txt'; do total=$(echo $total+$i | bc); ((count++)); done;
  926  history
  927  total=0;count=0;
  928  for i in `cat 51204643.helpfulnessReviews.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
  929  echo $total $count
  930  cd totalCount
  931  ls
  932  cat 51204643.totalCount.txt
  933  cat 33993847.totalCount.txt
  934  cd ..
  935  rm -r totalCount
  936  mkdir totalCount
  937  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));     done;      echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  938  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));     done;      echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;  done;
  939  for i in $UNIQ_IDS; do >     for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do
  940  >         total=$(echo $total+$i | bc); ((count++));
  941  >     done;
  942  >      echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
  943  >  done;
  944  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  945  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
  946  ls
  947  rm done echo 
  948  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
  949  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$i | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  950  rm -r totalCount
  951  mkdir totalCount
  952  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  953  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.helpfulnessReviews.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  954  ls
  955  cd totalCount
  956  ls
  957  cat 33993847.totalCount.txt
  958  cd ..
  959  rm -r totalCount
  960  mkdir totalCount
  961  total=0;count=0;
  962  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.helpfulnessReviews.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  963  cd totalCount
  964  w
  965  ls
  966  cat 33993847.totalCount.txt
  967  cat 51204643.totalCount.txt
  968  total=0; count=0;
  969  cd ..
  970  rm -r totalCount
  971  ls
  972  cat 33993847.helpfulnessReviews.txt
  973  cd ~/WS4
  974  ls
  975  cd CUSTOMERS
  976  ls
  977  cd ..
  978  cd PRODUCTS
  979  ls
  980  cat 0316666343.txt
  981  ls
  982  total=0;count=0;
  983  cd ..
  984  ls
  985  cat 0316666343.helpfulness.txt
  986  cd PRODUCTS
  987  0316666343.helpfulness.txt
  988  cat 0316666343.helpfulness.txt
  989  cd ~/A2
  990  ls
  991  cd PRODUCTS
  992  l
  993  sls
  994  l
  995  ls
  996  cat 0060193395.helpfulnessReviews.txt
  997  cd ..
  998  ls
  999  head -n 1 amazon_reviews_us_Books_v1_02.tsv
 1000  cd tempProducts
 1001  cd ..
 1002  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
 1003  cd tempProducts
 1004  ls
 1005  cd ../PRODCUTS
 1006  cd ../PRODUCTS
 1007  ls
 1008  mkdir starRating
 1009  cd ../tempProducts
 1010  for i in $UNIQ_IDS; do cut -d "    " -f 8 $i.txt > ~/A2/PRODUCTS/starRating/$i.stars.txt; done
 1011  for i in $UNIQ_IDS; do cut -d "	" -f 8 $i.txt > ~/A2/PRODUCTS/starRating/$i.stars.txt; done
 1012  cd../PRODCUTS
 1013  cd../PRODUCTS
 1014  cd..
 1015  cd ../PRODUCTS
 1016  ls
 1017  cd starRating
 1018  ls
 1019  cat 0060193395.stars.txt
 1020  ls
 1021  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.stars.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
 1022  mkdir totalCount
 1023  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.stars.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1024  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1025  ls
 1026  cd totalCount
 1027  ls
 1028  cat 0060193395.totalCount.txt
 1029  cat 014131088X.totalCount.txt
 1030  cat 0060514558.totalCount.txt
 1031  cat 0399142789.totalCount.txt
 1032  cat 0066214130.totalCount.txt
 1033  cd ..
 1034  rm -r starRating
 1035  cd totalCount
 1036  ls
 1037  cat 0156027321.totalCount.txt
 1038  cd ..
 1039  rm -r totalCount
 1040  ls
 1041  cat 0316011770.stars.txt
 1042  cat 0060193395.stars.txt
 1043  ls
 1044  echo $total
 1045  total=0;count=0;
 1046  ls
 1047  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1048  echo $total $count
 1049  mkdir totalCount
 1050  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1051  cd totalCount
 1052  l
 1053  sls
 1054  ls
 1055  cat 0060193395.totalCount.txt
 1056  cat  0060761288.totalCount.txt
 1057  cd ..
 1058  rm totalCount
 1059  rm -r  totalCount
 1060  echo $total
 1061  echo $count
 1062  total=0;count=0;
 1063  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1064  echo $total $count
 1065  cd ..
 1066  ls
 1067  cd ..
 1068  ls
 1069  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
 1070  echo $UNIQ_IDS
 1071  cd PRODUCTS
 1072  cd starRating
 1073  ls
 1074  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1075  ls
 1076  mkdir totalCount
 1077  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1078  ls
 1079  cd totalCount
 1080  ls
 1081  cat 0060193395.totalCount.txt
 1082  cd ..
 1083  rm -r totalCount
 1084  total=0;count=0;
 1085  ls
 1086  mkdir totalCount
 1087  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1088  ls
 1089  cd totalCount
 1090  ls
 1091  cat 0060193395.totalCount.txt
 1092  cd..
 1093  cd ..
 1094  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1095  echo $total $count
 1096  total=0; count=0;
 1097  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1098  echo $total $count
 1099  la
 1100  rm totalCount
 1101  rm -r totalCount
 1102  mkdirtotalCount
 1103  mkdir totalCount
 1104  total=0;count=0;
 1105  for i in $UNIQ_IDS; do     for j in `cat $UNIQ_IDS.stars.txt`; do         total=$(echo $total+$j | bc); ((count++));     done;     echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;     count=0;total=0;   done;
 1106  ls
 1107  cd totalCout
 1108  cd totalCount
 1109  ls
 1110  cat 0060193395.totalCount.txt
 1111  cd ..
 1112  total=0;count=0;
 1113  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1114  echo $total $count
 1115  tmux
 1116  ls
 1117  cd WS5
 1118  ls
 1119  cd tempCustomers
 1120  ls
 1121  cd ..
 1122  rm tempCustomers
 1123  rm -r  tempCustomers
 1124  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1125  for i in {1..10}; do echo "$i"; done;
 1126  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i"; done;
 1127  ls
 1128  mkdir tempCustomers
 1129  ls
 1130  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i"; done;
 1131  ls
 1132  cd WS5
 1133  ls
 1134  cd tempCustomers
 1135  ls
 1136  cat UNIQ_IDS.txt
 1137  rm UNIQ_IDS.txt
 1138  ls
 1139  mkdir tempCustomers
 1140  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i" ; done;
 1141  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1142  ls
 1143  cd tempCustomers
 1144  ls
 1145  cd ..
 1146  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i" ; done;
 1147  ls
 1148  cd tempCustomers
 1149  ls
 1150  w
 1151  cd ..
 1152  head -n 1 amazon_reviews_us_Books_v1_02.tsv
 1153  cd
 1154  ls
 1155  cd WS5
 1156  ls
 1157  mkdir CUSTOMERS
 1158  for i in $UNIQ_IDS; do cut -d "	" -f 13, 14, 15 $i.txt > ~/WS5/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1159  echo $UNIQ_IDS
 1160  ls
 1161  cd CUSTOMERS
 1162  ls
 1163  cat 53063505.helpfulnessReviews.txt
 1164  cat 52974218.helpfulnessReviews.txt
 1165  cd ..
 1166  rm -r CUSTOMERS
 1167  ls
 1168  cd tempCustomers
 1169  ls
 1170  cat  53018444.txt
 1171  head -n 1 53018444.txt
 1172  cd ..
 1173  ls
 1174  mkdir CUSTOMERS
 1175  cd tempCustomers
 1176  ls
 1177  for i in $UNIQ_IDS; do cut -d "   " -f 13,14,15 $i.txt > ~/A2/CUSTOMERS/$i.Reviews.txt; done
 1178  cd ..
 1179  cd CUSTOMERS
 1180  w
 1181  l
 1182  ls
 1183  cd ..
 1184  cd tempCustomers
 1185  for i in $UNIQ_IDS; do cut -d "   " -f 13,14,15 $i.txt > ~/WS5/CUSTOMERS/$i.Reviews.txt; done
 1186  cd ../CUSTOMERS
 1187  ls
 1188  w
 1189  ls
 1190  rm customerids.1000.txt
 1191  head -1000 customerids.txt.sorted.uniqcount.reversed >customerids.1000.txt
 1192  ls
 1193  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1194  tmux
 1195  ls
 1196  cd WS5
 1197  ls
 1198  cd tempCustomers
 1199  ls
 1200  cd .. 
 1201  rm -r tempCustomers
 1202  cat ws5.txt
 1203  em ws5.txt
 1204  rm ws5.txt
 1205  ls
 1206  history
 1207  script ws5.txt
 1208  history > cmds.log
 1209  ls
 1210  cat ws5.txt
 1211  ls
 1212  git init
 1213  perl -pe 's/\x1b\[[0-9;]*[mG]//g' ws5.txt > ws5.txt.clean
 1214  tr -cd '\11\12\15\40-\176' < ws5.txt.clean > ws5.txt.clean2
 1215  ls
 1216  git add ws5.txt.clean2 cmds.log
 1217  git status
 1218  git commit -m "Worksheet 5"
 1219  git remote add origin https://github.com/mahir24/ws5.git
 1220  git push -u origin master
 1221  cd ..
 1222  cd A2
 1223  ls
 1224  history
 1225  clear
 1226  ls
 1227  cd CUSTOMERS
 1228  ls
 1229  cd ..
 1230  ls
 1231  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
 1232  cd tempCustomers
 1233  ls
 1234  for i in $UNIQ_IDS; do cut -d "    " -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1235  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1236  cd ../CUSTOMERS
 1237  ls
 1238  cd ..
 1239  rm -r CUSTOMERS
 1240  cd tempCustomers
 1241  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1242  cd ../CUSTOMERS
 1243  cd ..
 1244  mkdir CUSTOMERS
 1245  cd tempCustomers
 1246  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1247  cd ../CUSTOMRS
 1248  cd ../CUSTOMERS
 1249  ls
 1250  cd ..
 1251  ls
 1252  cd datamash-1.3
 1253  ls
 1254  for FILE in `ls `; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1255  for FILE in ../CUSTOMERS/.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1256  for FILE in ../CUSTOMERS/.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1257  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1258  ls
 1259  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1260  cd ..
 1261  ls
 1262  cd CUSTOMERS
 1263  ls
 1264  cd ..
 1265  cd datamash-1.3
 1266  ls
 1267  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1268  for FILE in ~/A2/CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; donefor FILE in ~/A2/CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; donecmd
 1269  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE' ; echo "$FILE $CORR" ; done
 1270  cd ..
 1271  cd CUSTOMERS
 1272  ls
 1273  for FILE in `ls `; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1274  for FILE in `ls `; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1275  cd ..
 1276  ls
 1277  cd  datamash-1.3
 1278  ls
 1279  cd ..
 1280  history >cmds.log
 1281  git init
 1282  git add cmds.log
 1283  ls
 1284  git status
 1285  git commit -m "Assignment 2" 
 1286  git remote add origin https://github.com/mahir24/a2.git
 1287  git push -u origin master
 1288  color 4
 1289  color a
 1290  ls
 1291  cd A1
 1292  ls
 1293  cat cmds.log
 1294  cd ..
 1295  history
 1296  clear
 1297  history
 1298  clear
 1299  kaiya = 'u luv it thooooo'
 1300  kaiya='u luv it thooooo'
 1301  echo $kaiya
 1302  clear
 1303  echo $kaiya
 1304  clear
 1305  echo $kaiya
 1306  clear
 1307  echo $kaiya
 1308  clear
 1309  arnie='red pill brother yee haw'
 1310  clear
 1311  $arnie
 1312  arnie="red pill brother yee haw"
 1313  clear
 1314  echo $arnie
 1315  clear
 1316  $kaiya
 1317  echo $kaiya
 1318  clear
 1319  cd ../WS4
 1320  cp customerids.txt.sorted.uniqcount.reversed ../WS5
 1321  cd ../WS5
 1322  ls
 1323  head -1000 customerids.txt.sorted.uniqcount.reversed >customerids.1000.txt
 1324  wc customerids.1000.txt
 1325  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1326  mkdir tempCustomers
 1327  cd ../WS4
 1328  cp amazon_reviews_us_Books_v1_02.tsv ../WS5
 1329  cd ../WS5
 1330  ls
 1331  for i in $UNIQ_IDS; do egrep "   $i       " amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt;
 1332  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt;
 1333  for in in $UNIQ_IDS;do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
 1334  ls
 1335  cd tempCustomers
 1336  ls
 1337  cd ..
 1338  for i in UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
 1339  ls
 1340  tempCustomers
 1341  cd tempCustomers
 1342  ls
 1343  cat UNIQ_IDS.txt
 1344  cd ..
 1345  ls
 1346  for i in {1..10}; echo $i;done;
 1347  ls
 1348  mkdir WS5
 1349  ls
 1350  cd WS4
 1351  ls
 1352  cd ..
 1353  cd WS5
 1354  script ws5.txt
 1355  tmux ls
 1356  tmux attach -t 0
 1357  tmux ls
 1358  cal
 1359  ls
 1360  a1
 1361  cd A1
 1362  ls
 1363  sort cmds.log
 1364  sort -ro cmds.log
 1365  sort -ro cmds.log test
 1366  sort -ro cmds.log test.txt
 1367  sort -r -o cmds.log test.txt
 1368  ls >cmds.log
 1369  ls
 1370  cmds .log
 1371  cat cmds.log
 1372  cs ..
 1373  cd ..
 1374  vi
 1375  sort cmds.log &
 1376  cd A1
 1377  cd ..
 1378  ls
 1379  cd ws1
 1380  ls
 1381  cd ws1
 1382  ls
 1383  cd WS1
 1384  ls
 1385  cat cmds.log
 1386  sort cmds.log &
 1387  cd ..
 1388  ls
 1389  cd WS2
 1390  ls
 1391  cd ..
 1392  cp WS2 MT
 1393  cp -r WS2 MT
 1394  ls
 1395  cd MT
 1396  ls
 1397  ls ??
 1398  echo $home
 1399  echo $HOME
 1400  echo $PATH
 1401  echo $home
 1402  echo home
 1403  echo HOME
 1404  pwd
 1405  echo " \"UNIX\" "
 1406  ls ?.txt
 1407  touch a.txt
 1408  ls
 1409  ls ?.txt
 1410  find . -type f -name "?"  -print
 1411  find . -type f -name "?.*"  -print
 1412  find  / -type f -name "file?"  -print   2>/dev/null
 1413  find  / -type f -name "cmd?.log"  -print   2>/dev/null
 1414  find  / -type f -name "cmd?"  -print   2>/dev/null
 1415  find  / -type f -name "verified?"  -print   2>/dev/null
 1416  cd ..
 1417  cd A2
 1418  ls
 1419  cd PRODUCTS
 1420  ls
 1421  cp 0743222245.helpfulnessReviews.txt ~/WS6
 1422  cd ~/WS6
 1423  la
 1424  export DATETIME=`date "+%Y%m%d_%H%M%S"`
 1425  DATETIME=`date "+%Y%m%d_%H%M%S"`
 1426  export DATETIME=`date "+%Y%m%d_%H%M%S"`
 1427  echo $DATETIME
 1428  ls
 1429  cp 0743222245.helpfulnessReviews.txt 0743222245.helpfulnessReviews.$DATETIME.txt
 1430  ls
 1431  ln -s 0743222245.helpfulnessReviews.20211015_000440.txt 0743222245.LATEST.txt
 1432  l
 1433  cronfile
 1434  crontab cronfile
 1435  crontab WS6
 1436  crontab ~/WS6
 1437  vi cronfile
 1438  cat cronfile
 1439  crontab cronfile
 1440  cronttab -l
 1441  crontab -l
 1442  ls
 1443  l
 1444  ls
 1445  crontab -l
 1446  l
 1447  ls
 1448  vi cronfile
 1449  crontab -l
 1450  crontab cronfile
 1451  crontab -l
 1452  vi cronfile
 1453  crontab -l
 1454  crontab cronfile
 1455  crontab -l
 1456  l
 1457  cat 0743222245.AVERAGE.txt
 1458  script ws6.txt
 1459  history >cmds.log
 1460  cat cmds.log
 1461  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a.txt > a.txt.clean
 1462  perl -pe 's/\x1b\[[0-9;]*[mG]//g' ws6.txt > ws6.txt.clean
 1463  tr -cd '\11\12\15\40-\176' < ws6.txt.clean > ws6.txt.clean2
 1464  ls
 1465  less ws6.txt.clean2
 1466  git init
 1467  ls
 1468  git add cmds.log ws6.txt.clean2
 1469  rm a.txt.clean a.txt
 1470  ls
 1471  git status
 1472  git commit -m "Worksheet 6"
 1473  git remote add origin https://github.com/mahir24/WS6.git
 1474  git push -u origin master
 1475  cd ..
 1476  cd A1
 1477  l
 1478  cd ..
 1479  cd A2
 1480  l
 1481  cp amazon_reviews_us_Books_v1_02.tsv ~/WS7
 1482  cd ~/WS7
 1483  l
 1484  head -1 amazon_reviews_us_Books_v1_02.tsv
 1485  awk '{print $14}' amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1486  w  amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1487  vi amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1488  cat amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1489  l
 1490  cat  amazon_reviews_us_Books_v1_02.tsv
 1491  rm amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1492  head -1 amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1493  l
 1494  head -1 amazon_reviews_us_Books_v1_02.tsv
 1495  awk {print $14} amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1496  awk '{print $14}' amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1497  sed -i 's/<[a-z][a-z] \/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1498  vi amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1499  sed -i 's/<br_\/>//g" amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1500  sed -i 's/<br_\/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1501  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1502  sed -i 's/<[a-zA-Z]\+ \/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1503  l
 1504  head -n 11 amazon_reviews_us_Books_v1_02.tsv > amazonReview.10lines.txt
 1505  cat amazonReview.10lines.txt
 1506  sed -i 's/<[a-zA-Z]\+ \/>//g' amazonReview.10lines.txt
 1507  cat amazonReview.10lines.txt
 1508  awk '{print $14}' amazonReview.10lines.txt > amazonReviewBody.10lines.txt
 1509  cat amazonReviewBody.10lines.txt
 1510  rm  amazonReviewBody.10lines.txt
 1511  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1512  cat amazonReviewBody.10lines.txt
 1513  cat amazonReview.10lines.txt
 1514  sed -i 's/,//g' amazonReview.10lines.txt
 1515  cat amazonReview.10lines.txt
 1516  sed -i 's/.//g' amazonReview.10lines.txt
 1517  cat amazonReview.10lines.txt
 1518  rm amazonReview.10lines.txt
 1519  head -n 11 amazon_reviews_us_Books_v1_02.tsv > amazonReview.10lines.txt
 1520  sed -i 's/\.//g' amazonReview.10lines.txt
 1521  cat amazonReview.10lines.txt
 1522  sed -i 's/,//g' amazonReview.10lines.txt
 1523  cat amazonReview.10lines.txt
 1524* sed -i 's/\<\>//g' amazonReview.10lines.txt
 1525  vi amazonReview.10lines.txt
 1526  sed -i 's/\<if\>//g' amazonReview.10lines.txt
 1527  vi amazonReview.10lines.txt
 1528  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1529  cat amazonReview.10lines.txt
 1530  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1531  cat amazonReview.10lines.txt
 1532  sed -i 's/<[a-zA-Z]\+ \/>//g' amazonReview.10lines.txt
 1533  cat amazonReview.10lines.txt
 1534  history > cmds.log
